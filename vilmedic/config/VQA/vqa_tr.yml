name: myvqa
ckpt_dir: ckpt

dataset:
  proto: ImLabel
  label:
    root: data/2021-VQA
    file: a.txt

  image:
    root: data/2021-VQA
    image_path: data/2021-VQA/images
    file: ids.txt
    load_memory: False
    resize: (232, 232)
    ext: .jpg

model:
  proto: VQA_tr
  visual:
    proto: CNN
    backbone: densenet169
    output_layer: features
    dropout_out: 0.0
    permute: batch_first
    freeze: False

  adapter:
    input_size: 1664
    output_size: 768

  transformer:
    hidden_size: 768
    intermediate_size: 2048
    num_hidden_layers: 12
    num_attention_heads: 8
    attention_probs_dropout_prob: 0.1
    hidden_dropout_prob: 0.1
    hidden_act: gelu
    initializer_range: 0.02
    layer_norm_eps: 1.e-12

  classif:
    input_size: 768
    num_classes: 330

  loss:
      proto: LabelSmoothingCrossEntropy
#      proto: MixUpLoss
#      criterion: LabelSmoothingCrossEntropy
#      classes: 332


trainor:
  optimizer: Adam
  optim_params: {lr: 1e-4, weight_decay: 5e-4}
  batch_size: 32
  lr_decay_factor: 0.5
  lr_decay_patience: 2
  lr_min: 0.000001
  epochs: 99
  early_stop: 10
  eval_start: 0
  early_stop_metric: accuracy

validator:
  batch_size: 16
  metrics: [accuracy]
  post_processing: [attentions]
  splits: [val]

ensemblor:
  batch_size: 16
  metrics: [accuracy]
  post_processing: [attentions]
  splits: [val]
  mode: all # best,all