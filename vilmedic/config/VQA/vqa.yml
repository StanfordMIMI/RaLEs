name: myvqa
ckpt_dir: ckpt

dataset:
  proto: ImLabel
  label:
    root: data/2021-VQA
    file: a.txt

  image:
    root: data/2021-VQA
    image_path: data/2021-VQA/images
    file: ids.txt
    load_memory: False
    resize: (232, 232)
    ext: .jpg

model:
  proto: VQA_tr
  cnn:
    proto: CNN
    backbone: densenet169
    output_layer: features
    dropout_out: 0.0
    permute: batch_first
    freeze: False

  adapter:
    input_size: 1664
    output_size: 768

  transformer:
    hidden_size: 768
    intermediate_size: 2048
    num_hidden_layers: 12
    num_attention_heads: 8
    attention_probs_dropout_prob: 0.1
    hidden_dropout_prob: 0.1
    hidden_act: gelu
    initializer_range: 0.02
    layer_norm_eps: 1.e-12

  classifier:
    proto: Classifier
    input_size: 768
    num_classes: 330
    dropout: 0.

  loss:
      proto: LabelSmoothingCrossEntropy
#      proto: MixUpLoss
#      criterion: LabelSmoothingCrossEntropy
#      classes: 332


trainor:
  optimizer: Adam
  optim_params: {lr: 1e-4, weight_decay: 5e-4}
  batch_size: 32
  lr_decay: ReduceLROnPlateau
  lr_decay_params:
    factor: 0.5
    patience: 1
    min_lr: 0.000001
    threshold_mode: abs
  epochs: 99
  early_stop: 10
  eval_start: 0
  early_stop_metric: accuracy

validator:
  batch_size: 16
  metrics: [accuracy]
#  post_processing: [attentions]
  splits: [val]

ensemblor:
  batch_size: 16
  metrics: [accuracy]
#  post_processing: [attentions]
  splits: [val, test]
  mode: all